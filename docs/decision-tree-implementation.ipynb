{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A first attempt at implementing a decision tree algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coming back to this after long time off. On second look it should be two separate classes:\n",
    "\n",
    "- a decision stump that deals with the split on a given subset of data \n",
    "- a decision tree that is just a collection of decision stumps (plus a little extra stuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class decision_tree_classifier():\n",
    "\n",
    "    def __init__(self, d):\n",
    "        \n",
    "        ## lots more stuff needs to go in here\n",
    "        ## need to place store rules as the are \n",
    "        ## found at each level of the recursion\n",
    "        ## maybe label names and predictor names?\n",
    "        \n",
    "        self.d = d\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "\n",
    "    def fit(self, y, X):\n",
    "\n",
    "        ## this is where the work happens\n",
    "        ## roughly speaking the goal is to construct a sequence of \n",
    "        ## if else statement that send a new observation to the leaf\n",
    "        ## that has a label we'll assign to it\n",
    "        \n",
    "        ## just binary splits right?\n",
    "        ## greedy recursive splitting\n",
    "        \n",
    "        ## goes something like this:\n",
    "            \n",
    "            ## first call: find the predictor for which we get the 'best' split \n",
    "            ## we'll go with node purity 'gini' index for now but keep the \n",
    "            ## information gain in the back of your head\n",
    "            \n",
    "            ## recurse!-> form another split on each of the zones created by the last partition\n",
    "            \n",
    "            ## .\n",
    "            ## .\n",
    "            ## .\n",
    "            \n",
    "            ## hit the base case: - nodes have one observation\n",
    "            ##                    - reached maximum depth\n",
    "            ##                    - our splits are meeting 'best' criteria?\n",
    "            \n",
    "        \n",
    "        ## base case goes here\n",
    "        ## contents of leaf condition \n",
    "        ## or splitting criterion condition (how would that work here)\n",
    "        \n",
    "        ## we'll call X an n x p array for the purposes of discussion throughout\n",
    "        \n",
    "        ## for each predictor\n",
    "        for i in range(X.shape[1]):\n",
    "            \n",
    "            ## for each unique level in ith predictor\n",
    "            ## this part sounds like it could be a nighmare\n",
    "            ## consider this:\n",
    "            ## https://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.unique.html\n",
    "            for j in range(X[:,i]):\n",
    "                \n",
    "                ## check if split at jth levelof ith predictor yields the best yet split\n",
    "                ## if so, store this 'rule' \n",
    "                pass\n",
    "                \n",
    "        ## once we've exhausted all possible splits \n",
    "        ## i.e. seen all combinations of (i,j)\n",
    "        ## we should split the dataset(?) on the best rule and call\n",
    "        ## fit recursively on these distinct areas of the dataset.\n",
    "        \n",
    "        ## this sounds like it will MURDER the computers memory for \n",
    "        ## any reasonable sized dataset\n",
    "        ## need to think about all this more\n",
    "        \n",
    "        ## once we hit the base case we should end up returning a sequence of rules \n",
    "        ## our object structure will need to be much more complicated than it \n",
    "        ## was in the k-nn case\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        ## should just be a matter of applying the rules \n",
    "        ## we establish as we recurse\n",
    "\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.array([[1,2,3],[43,2,4],[1,3,3]])\n",
    "np.unique(t[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
